[build-system]
requires = ["hatchling", "hatch-vcs"]
build-backend = "hatchling.build"

[tool.hatch.version]
source = "vcs"

[tool.hatch.build.targets.wheel]
packages = ["src/dandi_s3_log_extraction"]

[tool.hatch.metadata]
allow-direct-references = true



[project]
name = "dandi-s3-log-extraction"
version="0.0.1"
authors = [
  { name="Cody Baker", email="cody.c.baker.phd@gmail.com" },
]
description = "Fast extraction of access summary data from DANDI S3 logs."
readme = "README.md"
keywords = [
    "AWS",
    "S3",
    "logging",
    "access stats",
    "usage analysis",
    "download tracking",
    "geolocation",
    "open data",
    "DANDI archive",
    "data infrastructure",
]
license = {file = "LICENSE.txt"}
requires-python = ">=3.13"
dependencies = [
    "pandas",
    "tqdm",
    "PyYAML",
    "rich_click",
    "natsort",
    "psutil",
    "cryptography",
    "dandi",
    "s3_log_extraction @ git+https://github.com/dandi/s3-log-extraction.git@main",  # TODO: release
]
classifiers = [
    "Development Status :: 5 - Production/Stable",
    "Programming Language :: Python",
    "Programming Language :: Python :: 3.13",
    "Intended Audience :: Developers",
    "Operating System :: Unix",
    "Operating System :: MacOS",
    "Topic :: Scientific/Engineering :: Information Analysis",
    "License :: OSI Approved :: MIT License",
]

[project.optional-dependencies]
geolocation = [
    "ipinfo",
    "opencage",
]
remote = [
    "fsspec",
    "s3fs",
    "s5cmd",
]
sharing = [
    "polars",
]
all = ["dandi_s3_log_extraction[geolocation,remote,sharing]"]

[project.urls]
Homepage = "https://dandi.github.io/access-page/"
Documentation = "https://github.com/dandi/dandi-s3-log-extraction/blob/master/README.md"
Repository = "https://github.com/dandi/dandi-s3-log-extraction/"
Issues = "https://github.com/dandi/dandi-s3-log-extraction/issues"
Changelog = "https://github.com/dandi/dandi-s3-log-extraction/blob/master/CHANGELOG.md"

[project.scripts]
dandis3logextraction = "dandi_s3_log_extraction._command_line_interface._cli:_dandis3logextraction_cli"

[dependency-groups]
test = ["pytest"]
coverage = ["pytest-cov", "pytest-env", "coverage[toml]"]
dev = ["ipython", "pre-commit"]
all = [
    {include-group = "test"},
    {include-group = "coverage"},
    {include-group = "dev"}
]



[tool.black]
line-length = 120
target-version = ['py312']
include = '\.pyi?$'
extend-exclude = '''
/(
  \.toml
  |\.yml
  |\.txt
  |\.sh
  |\.git
  |\.ini
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | build
  | dist
)/
'''



[tool.ruff]
exclude = [
  "*/__init__.py"
]
line-length = 120

[tool.ruff.lint]
select = ["F", "E", "I"]
ignore = [
    "PTH123",
    "D203",
    "D212",
    "T201",
    "FIX002",
    "TD003",
    "TD002",
    "S101",
    "ICN001",
    "INP001",
    "F821",  # Only way to do annotation of lazy imports...
]
fixable = ["ALL"]

[tool.ruff.lint.isort]
relative-imports-order = "closest-to-furthest"
known-first-party = ["dandi_s3_log_extraction"]

[tool.ruff.lint.per-file-ignores]
"src/dandi_s3_log_extraction/_hidden_top_level_imports.py" = ["F401"]  # Must perform imports here even if not exposed


# None of these environment variables need to be 'correct' with respect to test suite
[tool.pytest.ini_options]
markers = [
    "remote: mark a test as requiring remote resources",
]



[tool.coverage.run]
# Enable subprocess coverage to capture coverage from CLI commands run in subprocesses
concurrency = ["thread", "multiprocessing"]
parallel = true
source = ["src/dandi_s3_log_extraction"]
# Enable coverage for code running in subprocesses (e.g., CLI commands)
sigterm = true

[tool.coverage.report]
# Configure coverage reporting
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise AssertionError",
    "raise NotImplementedError",
    "if __name__ == .__main__.:",
    "if TYPE_CHECKING:",
    "if typing.TYPE_CHECKING:",
]

[tool.coverage.paths]
# Map different paths to the same source (for combining parallel coverage)
source = [
    "src/dandi_s3_log_extraction",
    "*/dandi_s3_log_extraction",
]
